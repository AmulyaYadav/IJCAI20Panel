---
layout: post
title: Maimuna Majumdar
date: 2020-12-12 00:00:00 +0300
description: You’ll find this post in your `_posts` directory. Go ahead and edit it and re-build the site to see your changes. # Add post description (optional)
img: maia.jpeg # Add image post (optional)
tags: [Programming, Learn] # add tag
---

Dr. Maimuna (Maia) Majumder is a computational epidemiologist specializing in emerging epidemics and a recent graduate of the Engineering Systems program at MIT’s Institute for Data, Systems, and Society (IDSS). In between her graduate studies and her current position at CHIP, Maia spent a year at the Health Policy Data Science lab at Harvard Medical School’s Health Care Policy department as a postdoctoral fellow. During her masters and doctoral studies at MIT, she was funded through a graduate fellowship at HealthMap. Prior to Maia’s arrival at MIT, she earned a Bachelors of Science in Engineering Science (with a concentration in Civil and Environmental Engineering) and a Masters of Public Health in Epidemiology and Biostatistics at Tufts University. While at Tufts, Maia was a field researcher with the International Centre for Diarrheal Disease Research, Bangladesh (ICDDR,B), where she worked with clinic patients (and their data) to learn how to better tell their stories. Her current research interests involve probabilistic modeling, artificial intelligence, and “systems epidemiology” in the context of public health, with a focus on causal inference for infectious disease surveillance using digital disease data (e.g. search trends; news and social media). She also enjoys exploring novel techniques for data procurement, writing about data for the general public, and creating meaningful data visualizations. As of January 2019, Maia has been engaged in pandemic response efforts and is a leading expert in COVID-19 epidemiology. 



## Transmission Modeling, NLP and Search for COVID-19 

My research group became involved in COVID-19 response efforts in January 2020, when we were one of the first teams to produce an estimate of the basic reproduction number for the novel coronavirus in Hubei, China. In epidemiology, the basic reproduction number – often abbreviated as “R-naught” – may be defined as the average number of secondary infections caused by a single index case in a fully susceptible population; as a result, it is population- specific and varies across contexts. If R-naught for a given pathogen in a given population is estimated to be greater than 1, we expect that the pathogen has epidemic or pandemic potential. Early on in the pandemic, when data were sparse, my team employed a simple phenomenological model to estimate R-naught. We found that R-naught for the novel coronavirus exceeded unity and was likely between 2 and 3 soon after its emergence, but as the epidemic in Hubei quickly turned into a global pandemic, my team started to wonder just how different R-naught was across locations – and how the various non-pharmaceutical interventions that were implemented around the world would impact transmission. 


The complexity of these questions – as well as the wealth of data that were generated in the first few months of the pandemic – warranted a transition away from phenomenological modeling and towards artificial intelligence approaches to modeling transmission dynamics. Together with Milind Tambe’s team, we developed a suite of agent-based models – or ABMs – to explore the heterogeneity of COVID-19 within and across three different populations, with a special focus on simulating the effect of non-pharmaceutical interventions. 
However, ABMs are just one example of an AI approach that my team has explored within the context of the pandemic. Prompted by the wealth of research that has been published since early 2020 about the novel coronavirus, we became increasingly curious about the speed at which the scientific community was working to fill existing knowledge gaps to better understand the novel coronavirus. We were especially interested in understanding whether certain fields within the broad umbrella of outbreak research were experiencing more rapid information generation than other, and thus we turned to natural language processing – or NLP – techniques to sift through the thousands and thousands of new studies that have been produced in response to the pandemic. 

Over the course of this bibliometrics analysis though, we started to wonder about how the very existence of gaps in knowledge might lend themselves to the proliferation of misinformation as well. Because of the political context of the pandemic in the United States, Americans have been particularly vulnerable to misinformation pertaining to the pandemic. Thus, with an eye towards developing AI-enabled monitoring and mitigation strategies for public health misinformation, my team tapped into novel digital data streams like news media data and search query data to investigate misinformation events here in the U.S. 

These three broad research areas – ABMs for transmission dynamics, NLP for bibliometrics, and news media and search query data for event-specific surveillance of misinformation events – will serve as my platform during the IJCAI AI for COVID-19 Panel, and I look forward to participating in a meeting of the minds on this important topic. 
